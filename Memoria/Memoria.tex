%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
% Instructions for using this template:
% This title page is capable of being compiled as is. This is not useful for 
% including it in another document. To do this, you have two options: 
%
% 1) Copy/paste everything between \begin{document} and \end{document} 
% starting at \begin{titlepage} and paste this into another LaTeX file where you 
% want your title page.
% OR
% 2) Remove everything outside the \begin{titlepage} and \end{titlepage} and 
% move this file to the same directory as the LaTeX file you wish to add it to. 
% Then add \input{./title_page_1.tex} to your LaTeX file where you want your
% title page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt,spanish]{article}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage[utf8]{inputenc}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}

\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Preprocesamiento y clasificación}\\[1.0cm] % Name of your university/college
\textsc{\Large Trabajo final}\\[0.5cm] % Major heading such as course name
\textsc{\large Memoria de la competición en Kaggle}\\[0.5cm] % Minor heading such as course title



 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------
\HRule
\vspace{2cm}

\begin{minipage}{1\textwidth}
\begin{flushleft} \small
Luis Suárez Lloréns\\
luissuarez@correo.ugr.es\\
Máster Universitario Oficial en Ciencia de Datos e Ingeniería de Computadores
\end{flushleft}
\end{minipage}

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

%\includegraphics{Logo}\\[1cm] % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}
\tableofcontents
\listoftodos
\newpage
\section{Introducción}
\todo{Arreglar las comillas de todo el documento}
Esta memoria, consiste en resumir el trabajo realizado en la competición interna en Kaggle. 

En este caso, el conjunto de datos utilizado contiene ejemplos de accidentes de tráfico. El objetivo es utilizar la información de la condición, localización y resultados de un accidente y clasificarlo dentro de algún tipo de accidente.

Vamos a dividir el trabajo en dos grandes secciones. La primera contendrá de manera resumida el proceso de generación del modelo final, pasando por todos los intentos y pruebas realizados en el camino.
\section{Proceso de trabajo}

\subsection{Entrega 1}

Entrega de prueba. Se toman 5 columnas sin valores perdidos del conjunto de datos y se utiliza un modelo de tipo 'Random Forest'. Entrega para comprobar que el proceso de subir resultados funciona correctamente.
\begin{itemize}
\item \textbf{Resultado en Kaggle público:} 0.56945.
\item \textbf{Resultado en Kaggle privado:} 0.56511.
\end{itemize}

\subsection{Entrega 2}
\begin{itemize}
\item \textbf{Preprocesamiento:} Tratamiento básico de los valores perdidos. Primero, añadimos una columna booleana por cada columna con datos perdidos que almacena si hemos imputado el dato o si ya se tenía en la base de datos original. Después, imputamos a mano, añadiendo el elemento más común. Eliminamos las columnas "CARRETERA" --- tiene demasiados posibles valores para ser usado directamente ---e "ISLAS" --- requiere procesamiento extra al faltar la isla "HIERRO" en el conjunto de entrenamiento--- . Se transforma la variable "HORA" de "factor" a "numeric".
\item \textbf{Selección de modelo:} Usamos un modelo XGBoost. Para seleccionar los hiperparámetros, realizamos una validación cruzada de 5 bloques. El mejor resultado obtuvo un accuracy de 0.8280115 en la validacion cruzada.
\item \textbf{Resultado en Kaggle público:} 0.82948.
\item \textbf{Resultado en Kaggle privado:} 0.82625.
\end{itemize}

\subsection{Entrega 3}
\begin{itemize}
\item \textbf{Preprocesamiento:} El mismo de la entrega 2.
\item \textbf{Selección de modelo:} En este caso, utilizamos un Random Forest. Para la selección de hiperparámetros, se utiliza igualmente una validación cruzada de 5 bloques. El mejor resultado obtuvo un accuracy de 0.8308112 en la validación cruzada.
\item \textbf{Resultado en Kaggle público:} 0.82948.
\item \textbf{Resultado en Kaggle privado:} 0.82625.
\end{itemize}

\subsection{Entrega 4}
\begin{itemize}
\item \textbf{Preprocesamiento:} Basado en la entrega 2. Se arregla el problema con la variable "ISLA", que pasa a poder usarse. Se arregla un pequeño bug que modificó las etiquetas de los meses del año y los días. Se añaden ratios relativos al número de muertos, heridos graves, heridos leves y vehículos implicados por víctima.
\item \textbf{Selección de modelo:} Utiliza un modelo Random Forest, pero con menos hiperparámetros que en la entrega 3, centrándonos en la zona de mejores resultados, con el objetivo de poder evaluar rápidamente los diferentes preprocesamientos que se aplican en las siguientes entregas. Tras realizar varios avances en el preprocesamiento, se volverá a probar un gran espacio de hiperparámetros. El mejor resultado obtuvo un accuracy de 0.8301113 en la validación cruzada.
\item \textbf{Resultado en Kaggle público:} 0.83156.
\item \textbf{Resultado en Kaggle privado:} 0.82827.
\end{itemize}

\subsection{Entrega 5}
\begin{itemize}
\item \textbf{Preprocesamiento:} Basado en la entrega 4. Se añade el concepto de "punto negro", es decir, las carreteras ---según la variable "CARRETERA"--- con más accidentes. El parámetro que controla el número de accidentes necesario para considerar una carretera peligrosa se fija a 50 y se explorará más adelante.
\item \textbf{Selección de modelo:} Igual que en entrega 4. El mejor resultado obtuvo un accuracy de 0.8306117 en la validación cruzada.
\item \textbf{Resultado en Kaggle público:} 0.83126.
\item \textbf{Resultado en Kaggle privado:} 0.82857.
\end{itemize}

\subsection{Entrega 6} %%Mejor privado
\begin{itemize}
\item \textbf{Preprocesamiento:} Basado en la entrega 5. Se añade una discretización manual de la variable hora en 4 segmentos: "MAÑANA", "TARDE", "NOCHE" y "MADRUGADA". Por el momento se preserva la variable "HORA" pero viendo la cantidad de atributos que empezamos a manejar, puede ser buena idea más adelante probar métodos de selección de características o de reducción de dimensionalidad.
\item \textbf{Selección de modelo:} Igual que en entrega 4. El mejor resultado obtuvo un accuracy de 0.8301113 en la validación cruzada.
\item \textbf{Resultado en Kaggle público:} 0.83185.
\item \textbf{Resultado en Kaggle privado:} 0.82918.
\end{itemize}

\subsection{Entrega 7}
\begin{itemize}
\item \textbf{Preprocesamiento:} Imput-1 (Sin acond_calzada)
\item \textbf{Selección de modelo:} CV 0.8301113
\item \textbf{Resultado en Kaggle público:} 0.83235.
\item \textbf{Resultado en Kaggle privado:} 0.82746.
\end{itemize}

\subsection{Entrega 8}
\begin{itemize}
\item \textbf{Preprocesamiento:} Imput-2 (con)
\item \textbf{Selección de modelo:} CV 0.8300447
\item \textbf{Resultado en Kaggle público:} 0.83225.
\item \textbf{Resultado en Kaggle privado:} 0.82736.
\end{itemize}

\subsection{Entrega 9} %%Mejor público
\begin{itemize}
\item \textbf{Preprocesamiento:} Mismo preprocesamiento que en la entrega 8.
\item \textbf{Selección de modelo:} Hasta ahora, hemos estado aplicando un modelo random forest para evaluar la utilidad de los preprocesamientos que hemos realizado. Vamos a volver a evaluar un modelo de boosting, XGBoost, con el objetivo de intentar mejorar el modelo directamente. Tras un proceso de selección de parámetros, el mejor resultado con un error de validación cruzada de 0.8331779 fue seleccionado.
\item \textbf{Resultado en Kaggle público:} 0.83393.
\item \textbf{Resultado en Kaggle privado:} 0.82857.
\end{itemize}

\subsection{Entrega 10}
\begin{itemize}
\item \textbf{Preprocesamiento:} Selección de características sobre el preprocesamiento realizado hasta el momento. Primero apliqué la técnica "Boruta", pero eliminó solo 3 variables y no mostraba ningún cambio significativo en la validación cruzada. Se decide aplicar sobre esta primera selección de características una segunda fase, tomando las 20 características mejor puntuadas según su importancia utilizando el algoritmo rfe del paquete "caret".
\item \textbf{Selección de modelo:} Mismo modelo que en la entrega 9. El resultado de la validación cruzada es 0.829780.
\item \textbf{Resultado en Kaggle público:} 0.83057.
\item \textbf{Resultado en Kaggle privado:} 0.82716.
\end{itemize}

\subsection{Entrega 11}
\begin{itemize}
\item \textbf{Preprocesamiento:} Eliminación de instancias ruidosas. En la entrega anterior, vemos un deterioro de la capacidad predictiva al eliminar atributos. Recuperamos el conjunto entero de atributos para realizar eliminación de ruido. Para ello utilizamos el paquete "NoiseFiltersR" y la función C45IterativeVotingFilter, ya que parece razonable que al ser un algoritmo que utiliza árboles para seleccionar las instancias, pueda comportarse bien con nuestro algoritmo de predicción.
\item \textbf{Selección de modelo:} Mismo proceso que aplicamos en la entrega 10. Se descarta el resultado de la validación cruzada pues al limpiar el ruido de los datos, el resultado de la validación cruzada no es comparable con los demás obtenidos.
\item \textbf{Resultado en Kaggle público:} 0.82701.
\item \textbf{Resultado en Kaggle privado:} 0.82371.
\end{itemize}

\section{Resumen del modelo final}


\end{document}